## Are LLMs Suddenly Better?

https://shumer.dev/something-big-is-happening

I saw this blog post shared on the socials.  At first, I felt the emotions the author was trying to evoke - a little bit of fear for my job, worry about the future if millions of white collar workers get laid off, a feeling that I need to jump on the AI train and learn all I can about how to prompt these tools into actually working.

Then I took a second look.  

The article was written on February 9th, 2026.   The author says: 

> on February 5th, two major AI labs released new models on the same day: GPT-5.3 Codex from OpenAI, and Opus 4.6 from Anthropic (the makers of Claude, one of the main competitors to ChatGPT). And something clicked. Not like a light switch... more like the moment you realize the water has been rising around you and is now at your chest.
> 
> **I am no longer needed for the actual technical work of my job.**

So in 4 days, the author evaluated both models and decided that they are both capable of replacing his technical contributions (whatever those may have been - a glance at his linked in reveals no engineering experience. It seems he graduated college and instantly became a founder and investor.  Must be nice). 

He goes on to say: 

> I describe what I want built, in plain English, and it just... appears. Not a rough draft I need to fix. The finished thing.... And when I test it, it's usually perfect.

Yet he provides no links to these perfect apps.  No github links to review the code, and no links to any perfectly working web app.  If it's so easy for him to just tell the computer what he wants and get it with no further input, you'd think he could provide at least one example.

I thought I'd ask if I could get an example of one of these apps, but there's no way to comment on his blog, or to get in touch with him except through the site formerly known as Twitter, which I will not use.  

Towards the bottom, he encourages people to sign up for the paid versions of these tools and use them. And I think that might be the real purpose of the post. Looking at his other blog posts and his Twitter, it's all hyping AI.  

Given the [recent revelations that tech companies have been paying huge sums to hype up their AI products](https://www.cnbc.com/2026/02/06/google-microsoft-pay-creators-500000-and-more-to-promote-ai.html), I don't put much faith in what this young man is saying.  

I also found it slightly humorous that he credits 3 humans with reviewing his post - apparently he didn't trust Claude or ChatGPT to do it for him.

End note:   I'm a couple days late in the hype cycle here, this article went viral 2 days ago and has had plenty of virtual ink spilled about it already.  I also use LLMs at my job developing software, and I've definitely observed some increases in productivity. But I've found it to be an augment at best, not a replacement.  
